<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@picocss/pico@1.5.11/css/pico.min.css"
  />
</head>
<body class="container">
<button id="start" class="secondary">Start</button>
<canvas id="drawing-area" class="container" width="640" height="480"></canvas>
<script>
const SAMPLE_RATE = 22050;
const ctx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
let segWs;
let heardWs;
let lookWs;
let lookVideo;
let lookCanvas;
let queue = [];
let texts = [];
let playing = false;
let pendingText = null;

function openSocket(existing, url, binaryType) {
  if (existing && existing.readyState <= WebSocket.OPEN) return existing;
  const s = new WebSocket(url);
  if (binaryType) s.binaryType = binaryType;
  return s;
}

function segmentDone() {
  pendingText = texts.shift() || null;
}

function sendHeard() {
  if (pendingText && heardWs && heardWs.readyState === WebSocket.OPEN) {
    heardWs.send(pendingText);
  } else if (pendingText) {
    console.warn(
      "heardWs not ready or no text to send",
      heardWs?.readyState,
      pendingText
    );
  }
  pendingText = null;
  console.log("Queue length", queue.length, "Texts length", texts.length);
}

function play() {
  if (playing || !queue.length) return;
  console.log("Queue length", queue.length, "Texts length", texts.length);
  playing = true;
  const pcm = queue.shift();
  if (pcm.length === 0) {
    playing = false;
    segmentDone();
    play();
    return;
  }
  const buf = ctx.createBuffer(1, pcm.length, SAMPLE_RATE);
  const chan = buf.getChannelData(0);
  for (let i = 0; i < pcm.length; i++) chan[i] = pcm[i] / 32768;
  const src = ctx.createBufferSource();
  src.buffer = buf;
  src.connect(ctx.destination);
  src.onended = () => {
    playing = false;
    sendHeard();
    play();
  };
  src.start();
}

function start() {
  segWs = openSocket(segWs, `ws://${location.host}/speech-segments-out`);
  if (segWs.readyState <= WebSocket.OPEN)
    segWs.onmessage = ev => {
      const seg = JSON.parse(ev.data);
      const bin = atob(seg.audio_b64);
      const buf = new Uint8Array(bin.length);
      for (let i = 0; i < bin.length; i++) buf[i] = bin.charCodeAt(i);
      queue.push(new Int16Array(buf.buffer));
      texts.push(seg.text);
      if (ctx.state === 'suspended') ctx.resume();
      play();
    };
  heardWs = openSocket(heardWs, `ws://${location.host}/speech-text-self-in`);
  heardWs.onopen = () => console.log("heardWs connected");
  heardWs.onerror = e => console.error("heardWs error", e);
  heardWs.onclose = () => console.warn("heardWs closed");
  lookWs = openSocket(lookWs, `ws://${location.host}/vision-jpeg-in`, 'arraybuffer');
  if (lookWs.readyState <= WebSocket.OPEN)
    lookWs.onmessage = ev => {
      if (ev.data === 'snap') capture();
    };
  navigator.mediaDevices.getUserMedia({ video: true }).then(s => {
    lookVideo = document.createElement('video');
    lookVideo.srcObject = s;
    lookVideo.play();
    lookCanvas = document.getElementById('drawing-area');
  });
  document.getElementById('start').style.display = 'none';
}

function capture() {
  if (!lookVideo) return;
  lookCanvas.width = lookVideo.videoWidth;
  lookCanvas.height = lookVideo.videoHeight;
  const ctx2d = lookCanvas.getContext('2d');
  ctx2d.drawImage(lookVideo, 0, 0);
  lookCanvas.toBlob(b => b && b.arrayBuffer().then(buf => lookWs.send(buf)), 'image/jpeg', 0.8);
}

// Attach the start handler only once so we don't open duplicate WebSocket
// connections if the user clicks multiple times.
document
  .getElementById('start')
  .addEventListener('click', start, { once: true });
</script>
</body>
</html>
