services:
  tts:
    image: ghcr.io/coqui-ai/tts
    ports:
      - "5002:5002"
    entrypoint: python3
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - COQUI_TOS_AGREED=1
      - TTS_MODEL="tts_models/en/ljspeech/tacotron2-DDC"
      - VOCODER_MODEL="vocoder_models/en/ljspeech/hifigan_v1"
    command: [ "TTS/server/server.py", "--model_name", "tts_models/en/vctk/vits" ]
    runtime: nvidia
    volumes:
      - ./tts:/root/.local/share
      - /etc/timezone:/etc/timezone:ro
    deploy:
      resources:
        reservations:
          devices:
            - count: all
              capabilities: [ gpu ]

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./vectors:/qdrant/storage

  neo4j:
    image: neo4j:5
    ports:
      - "7687:7687"
      - "7474:7474"
    environment:
      - NEO4J_AUTH=neo4j/password
    volumes:
      - ./graph:/data
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
